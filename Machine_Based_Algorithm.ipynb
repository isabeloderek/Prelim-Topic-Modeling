{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gTcykHs7NgWe",
        "outputId": "33fd3ec1-5a4c-451c-f02d-7c91be6bdf66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/andrianllmm/tagalog-stemmer.git@main\n",
            "  Cloning https://github.com/andrianllmm/tagalog-stemmer.git (to revision main) to /tmp/pip-req-build-mbm9ws0n\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/andrianllmm/tagalog-stemmer.git /tmp/pip-req-build-mbm9ws0n\n",
            "  Resolved https://github.com/andrianllmm/tagalog-stemmer.git to commit b5babfd4caebf8a8f480f8adab9f1c97f42a3baa\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: nltk>=3.8.1 in /usr/local/lib/python3.10/dist-packages (from tglstemmer==0.0.1) (3.8.1)\n",
            "Requirement already satisfied: tabulate>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from tglstemmer==0.0.1) (0.9.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>=3.8.1->tglstemmer==0.0.1) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>=3.8.1->tglstemmer==0.0.1) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>=3.8.1->tglstemmer==0.0.1) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk>=3.8.1->tglstemmer==0.0.1) (4.66.5)\n",
            "Building wheels for collected packages: tglstemmer\n",
            "  Building wheel for tglstemmer (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tglstemmer: filename=tglstemmer-0.0.1-py3-none-any.whl size=146663 sha256=2407416b9856af2477a88f468adfcd879f6bac9c64ad3d898d883fe1105f2a3e\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-pd19p0_j/wheels/8b/a1/58/0ac74f560df0e1894833f3d6d2b6efcf76b8cf603ebd847cf4\n",
            "Successfully built tglstemmer\n",
            "Installing collected packages: tglstemmer\n",
            "Successfully installed tglstemmer-0.0.1\n",
            "Collecting langdetect\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m38.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from langdetect) (1.16.0)\n",
            "Building wheels for collected packages: langdetect\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993221 sha256=602d9125581f7f6ce2139d97674855c2c1d5a07f3544b7b782b99ff8187b4be6\n",
            "  Stored in directory: /root/.cache/pip/wheels/95/03/7d/59ea870c70ce4e5a370638b5462a7711ab78fba2f655d05106\n",
            "Successfully built langdetect\n",
            "Installing collected packages: langdetect\n",
            "Successfully installed langdetect-1.0.9\n",
            "Collecting googletrans==4.0.0-rc1\n",
            "  Downloading googletrans-4.0.0rc1.tar.gz (20 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting httpx==0.13.3 (from googletrans==4.0.0-rc1)\n",
            "  Downloading httpx-0.13.3-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2024.8.30)\n",
            "Collecting hstspreload (from httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading hstspreload-2024.9.1-py3-none-any.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (1.3.1)\n",
            "Collecting chardet==3.* (from httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading chardet-3.0.4-py2.py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting idna==2.* (from httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading idna-2.10-py2.py3-none-any.whl.metadata (9.1 kB)\n",
            "Collecting rfc3986<2,>=1.3 (from httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading rfc3986-1.5.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting httpcore==0.9.* (from httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading httpcore-0.9.1-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting h11<0.10,>=0.8 (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading h11-0.9.0-py2.py3-none-any.whl.metadata (8.1 kB)\n",
            "Collecting h2==3.* (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading h2-3.2.0-py2.py3-none-any.whl.metadata (32 kB)\n",
            "Collecting hyperframe<6,>=5.2.0 (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading hyperframe-5.2.0-py2.py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting hpack<4,>=3.0 (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading hpack-3.0.0-py2.py3-none-any.whl.metadata (7.0 kB)\n",
            "Downloading httpx-0.13.3-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.1/55.1 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading chardet-3.0.4-py2.py3-none-any.whl (133 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.4/133.4 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-0.9.1-py3-none-any.whl (42 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading idna-2.10-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h2-3.2.0-py2.py3-none-any.whl (65 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.0/65.0 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n",
            "Downloading hstspreload-2024.9.1-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m59.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.9.0-py2.py3-none-any.whl (53 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hpack-3.0.0-py2.py3-none-any.whl (38 kB)\n",
            "Downloading hyperframe-5.2.0-py2.py3-none-any.whl (12 kB)\n",
            "Building wheels for collected packages: googletrans\n",
            "  Building wheel for googletrans (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for googletrans: filename=googletrans-4.0.0rc1-py3-none-any.whl size=17397 sha256=80fcfa781a82052c80ef1c71a2ee9f13f7fe348c6485d722750b66b6139da484\n",
            "  Stored in directory: /root/.cache/pip/wheels/c0/59/9f/7372f0cf70160fe61b528532e1a7c8498c4becd6bcffb022de\n",
            "Successfully built googletrans\n",
            "Installing collected packages: rfc3986, hyperframe, hpack, h11, chardet, idna, hstspreload, h2, httpcore, httpx, googletrans\n",
            "  Attempting uninstall: chardet\n",
            "    Found existing installation: chardet 5.2.0\n",
            "    Uninstalling chardet-5.2.0:\n",
            "      Successfully uninstalled chardet-5.2.0\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.10\n",
            "    Uninstalling idna-3.10:\n",
            "      Successfully uninstalled idna-3.10\n",
            "Successfully installed chardet-3.0.4 googletrans-4.0.0rc1 h11-0.9.0 h2-3.2.0 hpack-3.0.0 hstspreload-2024.9.1 httpcore-0.9.1 httpx-0.13.3 hyperframe-5.2.0 idna-2.10 rfc3986-1.5.0\n"
          ]
        }
      ],
      "source": [
        "# This command installs a Python package directly from a GitHub repository.\n",
        "# It uses pip to install the Tagalog Stemmer package from the repository hosted at the given URL.\n",
        "!pip install git+https://github.com/andrianllmm/tagalog-stemmer.git@main\n",
        "!pip install langdetect\n",
        "!pip install googletrans==4.0.0-rc1\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing necessary libraries\n",
        "import numpy as np  # For numerical operations\n",
        "import pandas as pd  # For data manipulation and analysis\n",
        "\n",
        "# Importing visualization libraries\n",
        "import matplotlib.pyplot as plt  # For plotting and data visualization\n",
        "from matplotlib import style  # For setting plot styles\n",
        "import seaborn as sns  # For advanced data visualization (heatmaps, categorical plots)\n",
        "\n",
        "# Importing Natural Language Toolkit (nltk) for NLP operations\n",
        "import nltk\n",
        "nltk.download('punkt')  # Downloading 'punkt' tokenizer for sentence and word tokenization\n",
        "\n",
        "# Importing functions from nltk for stopwords and tokenization\n",
        "from nltk.corpus import stopwords  # For using stopwords (commonly removed words like 'and', 'the')\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize  # Functions for word and sentence tokenization\n",
        "\n",
        "# Importing stemmers (for reducing words to their root form)\n",
        "from nltk.stem import PorterStemmer, LancasterStemmer  # Porter and Lancaster stemming algorithms\n",
        "\n",
        "# Importing WordNet lemmatizer (for converting words to their base form using linguistic rules)\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "# Importing Tagalog stemmer from the 'tglstemmer' package (assumed installed in earlier command)\n",
        "from tglstemmer import stemmer  # Tagalog language stemmer\n",
        "\n",
        "# Importing vectorizers from scikit-learn for creating document-term matrices (DTM)\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer  # TF-IDF and Count vectorization\n",
        "\n",
        "#Downloading 'stopwords'\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Defining a set of stop words for use in text processing\n",
        "stop_words = set(nltk.corpus.stopwords.words('english'))  # Stop words in English\n",
        "\n",
        "# Downloading 'wordnet' corpus for lemmatization\n",
        "nltk.download('wordnet')\n",
        "\n",
        "# Importing regular expression library for text manipulation and pattern matching\n",
        "import re  # For regex operations such as cleaning text data\n",
        "\n",
        "from langdetect import detect\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vEXxvYxhNl1I",
        "outputId": "60617dae-2ba1-4e88-c697-dde40bff6d67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reading Tagalog stopwords from a text file\n",
        "# 'tagalog_stop_words.txt' is assumed to be a file containing a list of stopwords in Tagalog.\n",
        "# The file is read as a DataFrame using pandas.\n",
        "tagalog_stopwords = pd.read_csv(\"tagalog_stop_words.txt\")\n",
        "\n",
        "# Extracting the 'stopwords' column from the DataFrame and converting it to a Python list\n",
        "# Assuming the file has a column named 'stopwords' that contains the actual stop words.\n",
        "tagalog_stopwords = tagalog_stopwords['stopwords'].tolist()\n",
        "\n",
        "# Output the list of Tagalog stopwords\n",
        "tagalog_stopwords\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eU5LenrTNp3y",
        "outputId": "03a3dcf7-ca77-411e-fc7d-172fd766c485"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ako',\n",
              " 'sa',\n",
              " 'akin',\n",
              " 'ko',\n",
              " 'aking',\n",
              " 'sarili',\n",
              " 'kami',\n",
              " 'atin',\n",
              " 'ang',\n",
              " 'aming',\n",
              " 'amin',\n",
              " 'ating',\n",
              " 'ka',\n",
              " 'iyong',\n",
              " 'iyo',\n",
              " 'inyong',\n",
              " 'siya',\n",
              " 'kanya',\n",
              " 'mismo',\n",
              " 'ito',\n",
              " 'nito',\n",
              " 'kanyang',\n",
              " 'sila',\n",
              " 'nila',\n",
              " 'kanila',\n",
              " 'kanilang',\n",
              " 'kung',\n",
              " 'ano',\n",
              " 'alin',\n",
              " 'sino',\n",
              " 'kanino',\n",
              " 'na',\n",
              " 'mga',\n",
              " 'iyon',\n",
              " 'am',\n",
              " 'ay',\n",
              " 'maging',\n",
              " 'naging',\n",
              " 'mayroon',\n",
              " 'may',\n",
              " 'nagkaroon',\n",
              " 'pagkakaroon',\n",
              " 'gumawa',\n",
              " 'ginagawa',\n",
              " 'ginawa',\n",
              " 'paggawa',\n",
              " 'ibig',\n",
              " 'dapat',\n",
              " 'maaari',\n",
              " 'marapat',\n",
              " 'kong',\n",
              " 'ikaw',\n",
              " 'tayo',\n",
              " 'hindi',\n",
              " 'namin',\n",
              " 'gusto',\n",
              " 'nais',\n",
              " 'niyang',\n",
              " 'nilang',\n",
              " 'niya',\n",
              " 'huwag',\n",
              " 'ginawang',\n",
              " 'gagawin',\n",
              " 'maaaring',\n",
              " 'sabihin',\n",
              " 'narito',\n",
              " 'kapag',\n",
              " 'ni',\n",
              " 'nasaan',\n",
              " 'bakit',\n",
              " 'paano',\n",
              " 'kailangan',\n",
              " 'walang',\n",
              " 'katiyakan',\n",
              " 'isang',\n",
              " 'at',\n",
              " 'pero',\n",
              " 'o',\n",
              " 'dahil',\n",
              " 'bilang',\n",
              " 'hanggang',\n",
              " 'habang',\n",
              " 'ng',\n",
              " 'pamamagitan',\n",
              " 'para',\n",
              " 'tungkol',\n",
              " 'laban',\n",
              " 'pagitan',\n",
              " 'panahon',\n",
              " 'bago',\n",
              " 'pagkatapos',\n",
              " 'itaas',\n",
              " 'ibaba',\n",
              " 'mula',\n",
              " 'pataas',\n",
              " 'pababa',\n",
              " 'palabas',\n",
              " 'ibabaw',\n",
              " 'ilalim',\n",
              " 'muli',\n",
              " 'pa',\n",
              " 'minsan',\n",
              " 'dito',\n",
              " 'doon',\n",
              " 'saan',\n",
              " 'lahat',\n",
              " 'anumang',\n",
              " 'kapwa',\n",
              " 'bawat',\n",
              " 'ilan',\n",
              " 'karamihan',\n",
              " 'iba',\n",
              " 'tulad',\n",
              " 'lamang',\n",
              " 'pareho',\n",
              " 'kaya',\n",
              " 'kaysa',\n",
              " 'masyado',\n",
              " 'napaka',\n",
              " 'isa',\n",
              " 'bababa',\n",
              " 'kulang',\n",
              " 'marami',\n",
              " 'ngayon',\n",
              " 'kailanman',\n",
              " 'sabi',\n",
              " 'nabanggit',\n",
              " 'din',\n",
              " 'kumuha',\n",
              " 'pumunta',\n",
              " 'pumupunta',\n",
              " 'ilagay',\n",
              " 'makita',\n",
              " 'nakita',\n",
              " 'katulad',\n",
              " 'mahusay',\n",
              " 'likod',\n",
              " 'kahit',\n",
              " 'paraan',\n",
              " 'noon',\n",
              " 'gayunman',\n",
              " 'dalawa',\n",
              " 'tatlo',\n",
              " 'apat',\n",
              " 'lima',\n",
              " 'una',\n",
              " 'pangalawa',\n",
              " 'yung',\n",
              " 'mo',\n",
              " 'lang',\n",
              " 'mag',\n",
              " 'ba',\n",
              " 'pag',\n",
              " 'yan',\n",
              " 'nga',\n",
              " 'rin',\n",
              " 'kasi',\n",
              " 'po',\n",
              " 'ung']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Combining English and Tagalog stopwords into a single list\n",
        "# The stopwords from nltk (in English) are combined with the Tagalog stopwords previously loaded from a file.\n",
        "# This allows you to remove both English and Tagalog stopwords from text in one step.\n",
        "all_stopwords = stopwords.words('english') + tagalog_stopwords\n",
        "\n",
        "# The resulting 'all_stopwords' will contain stopwords from both languages.\n"
      ],
      "metadata": {
        "id": "zAniA4AxNsTU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reading the English dataset from a CSV file\n",
        "# 'AI in edu dataset - Sheet1.csv' is assumed to contain text data in English.\n",
        "# The dataset is loaded as a pandas DataFrame.\n",
        "dataset = pd.read_csv('AI in edu dataset - Sheet1.csv')\n",
        "\n",
        "dataset = dataset.drop(dataset[dataset['Sentiment'] == 'Neutral' ].index)\n",
        "dataset = dataset.drop(dataset[dataset['Sentiment'] == 'neutral' ].index)\n",
        "\n",
        "dataset.dropna(subset = ['Sentiment'], inplace=True)\n",
        "\n",
        "# Converting all data in the dataset to string type\n",
        "# Ensures that all values in the DataFrame are treated as text, regardless of their original format.\n",
        "dataset = dataset.astype(str)"
      ],
      "metadata": {
        "id": "m_GDFMmiNtCt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset['Sentiment'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "nJUwFQ6JRGuY",
        "outputId": "9e07c9b2-5c84-4737-f265-11f2dca02a47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sentiment\n",
              "Positive    208\n",
              "Negative    162\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sentiment</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Positive</th>\n",
              "      <td>208</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Negative</th>\n",
              "      <td>162</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from nltk.corpus import wordnet\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "# Function to replace words with synonyms\n",
        "def synonym_replacement(sentence, n=2):\n",
        "    words = sentence.split()\n",
        "    new_sentence = words.copy()\n",
        "\n",
        "    random_word_list = list(set([word for word in words if wordnet.synsets(word)]))  # Only consider words that have synonyms\n",
        "\n",
        "    # Randomly select 'n' words to replace with their synonyms\n",
        "    random.shuffle(random_word_list)\n",
        "    num_replaced = 0\n",
        "    for random_word in random_word_list:\n",
        "        synonyms = wordnet.synsets(random_word)\n",
        "        if len(synonyms) > 0:\n",
        "            synonym = synonyms[0].lemmas()[0].name()  # Choose the first synonym\n",
        "            new_sentence = [synonym if word == random_word else word for word in new_sentence]\n",
        "            num_replaced += 1\n",
        "        if num_replaced >= n:\n",
        "            break\n",
        "\n",
        "    print('Done SR')\n",
        "    return ' '.join(new_sentence)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lERxEinPNvJa",
        "outputId": "846ab8d3-b9a1-48ab-bf78-e6713232758d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from googletrans import Translator\n",
        "\n",
        "# Function for back-translation\n",
        "def back_translate(sentence, lang='fr'):\n",
        "    translator = Translator()\n",
        "\n",
        "    # Translate the sentence to the target language\n",
        "    translated = translator.translate(sentence, src='en', dest=lang).text\n",
        "\n",
        "    # Translate it back to English\n",
        "    back_translated = translator.translate(translated, src=lang, dest='en').text\n",
        "\n",
        "    print('Done Translate')\n",
        "    return back_translated\n"
      ],
      "metadata": {
        "id": "38ggsk1HNyvK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a copy of the original dataset\n",
        "augmented_dataset = dataset.copy()\n",
        "\n",
        "# Apply synonym replacement to each row and append to the 'Content' column\n",
        "augmented_dataset['Content_Augmented_Synonym'] = augmented_dataset['Content'].apply(lambda x: synonym_replacement(x, n=1))\n",
        "\n",
        "# Apply back-translation and append to the 'Content' column\n",
        "augmented_dataset['Content_Augmented_BackTranslate'] = augmented_dataset['Content'].apply(lambda x: back_translate(x, lang='fr'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7MMUOj8ZN3yL",
        "outputId": "aca9a642-539b-48b9-da1e-c88e85203d53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done SR\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n",
            "Done Translate\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = augmented_dataset[['Content_Augmented_Synonym','Sentiment']]\n",
        "\n",
        "df2 = augmented_dataset[['Content_Augmented_BackTranslate','Sentiment']]\n",
        "df1.rename(columns = {'Content_Augmented_Synonym':'Content'}, inplace = True)\n",
        "df2.rename(columns = {'Content_Augmented_BackTranslate':'Content'}, inplace = True)\n",
        "\n",
        "dataset = pd.concat([df1, df2, dataset])\n",
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 602
        },
        "id": "xpZ9lx89N4VF",
        "outputId": "9fad117a-d0de-4218-ccfa-043a18bf0547"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-37-7389f391313b>:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df1.rename(columns = {'Content_Augmented_Synonym':'Content'}, inplace = True)\n",
            "<ipython-input-37-7389f391313b>:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df2.rename(columns = {'Content_Augmented_BackTranslate':'Content'}, inplace = True)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               Content Sentiment\n",
              "0    The education system that AI will destroy will...  Negative\n",
              "1    AI tool sare very helpful but you need to use ...  Positive\n",
              "2    AI and teachers should join forces in angstrom...  Positive\n",
              "3    Kids that learn how to use the AI will realize...  Negative\n",
              "4    But here’s the thing, if we embrace the AI, ho...  Negative\n",
              "..                                                 ...       ...\n",
              "413  AI be useful, pero dapat may balance sa paggam...  Negative\n",
              "414  Hindi pa tayo masyadong advanced sa Pilipinas,...  Negative\n",
              "415  Kailangan lang sodium maayos ang paggamit ng A...  Negative\n",
              "429  AI can be a powerful tool to enhance learning ...  Negative\n",
              "430  Pinangunahan ni Mayor Joy Belmonte ang turnove...  Positive\n",
              "\n",
              "[370 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e893946e-b7d7-4a6e-9a0b-7e1f71c8f6c4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Content</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The education system that AI will destroy will...</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>AI tool sare very helpful but you need to use ...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>AI and teachers should join forces in angstrom...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Kids that learn how to use the AI will realize...</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>But here’s the thing, if we embrace the AI, ho...</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>413</th>\n",
              "      <td>AI be useful, pero dapat may balance sa paggam...</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>414</th>\n",
              "      <td>Hindi pa tayo masyadong advanced sa Pilipinas,...</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>415</th>\n",
              "      <td>Kailangan lang sodium maayos ang paggamit ng A...</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>429</th>\n",
              "      <td>AI can be a powerful tool to enhance learning ...</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>430</th>\n",
              "      <td>Pinangunahan ni Mayor Joy Belmonte ang turnove...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>370 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e893946e-b7d7-4a6e-9a0b-7e1f71c8f6c4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e893946e-b7d7-4a6e-9a0b-7e1f71c8f6c4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e893946e-b7d7-4a6e-9a0b-7e1f71c8f6c4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-0edfc2e2-8986-40f4-93d4-d36bf59e3e56\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0edfc2e2-8986-40f4-93d4-d36bf59e3e56')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-0edfc2e2-8986-40f4-93d4-d36bf59e3e56 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_7bf76a66-9b9e-48d1-8fc2-4655ffa60413\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df1')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_7bf76a66-9b9e-48d1-8fc2-4655ffa60413 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df1');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df1",
              "summary": "{\n  \"name\": \"df1\",\n  \"rows\": 370,\n  \"fields\": [\n    {\n      \"column\": \"Content\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 368,\n        \"samples\": [\n          \"AI can automate administrative tasks, giving teachers more time to teach.\",\n          \"In large classes, students often don\\u2019t receive the individual attention they need. A one-size-fits-all approach only works for some, leading to boredom and low motivation. Teachers also face many challenges, including heavy administrative workloads, outdated materials, and difficulties in maintaining students\\u2019 attention. Should we continue down this path? With Army_Intelligence in your toolkit, you can tackle these problems. Army_Intelligence education can personalize learning, adjusting to each student\\u2019s pace and style and providing them with the support they need. Army_Intelligence can also take over routine administrative tasks, giving teachers more time to focus on teaching. Plus, Army_Intelligence tools can offer up-to-date resources and help ensure that students in remote areas have access to quality education.\",\n          \"Use ChatGPT and learn nothing, how will we ever advance as angstrom society\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sentiment\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Positive\",\n          \"Negative\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.concat([df1, df2, dataset])\n",
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "8482YHYhN7Fs",
        "outputId": "6f4ddb34-9a7a-46c1-de40-8d42fbe6ffb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               Content Sentiment   Platform\n",
              "0    The education system that AI will destroy will...  Negative        NaN\n",
              "1    AI tool sare very helpful but you need to use ...  Positive        NaN\n",
              "2    AI and teachers should join forces in angstrom...  Positive        NaN\n",
              "3    Kids that learn how to use the AI will realize...  Negative        NaN\n",
              "4    But here’s the thing, if we embrace the AI, ho...  Negative        NaN\n",
              "..                                                 ...       ...        ...\n",
              "413  AI is useful, pero dapat may balance sa paggam...  Negative        nan\n",
              "414  Hindi pa tayo masyadong advanced sa Pilipinas,...  Negative        nan\n",
              "415  Kailangan lang na maayos ang paggamit ng AI pa...  Negative        nan\n",
              "429  AI can be a powerful tool to enhance learning ...  Negative        nan\n",
              "430  Pinangunahan ni Mayor Joy Belmonte ang turnove...  Positive  X/Twitter\n",
              "\n",
              "[1110 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-76c43f2b-24c1-4e37-8748-bb747c6e47fc\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Content</th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>Platform</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The education system that AI will destroy will...</td>\n",
              "      <td>Negative</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>AI tool sare very helpful but you need to use ...</td>\n",
              "      <td>Positive</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>AI and teachers should join forces in angstrom...</td>\n",
              "      <td>Positive</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Kids that learn how to use the AI will realize...</td>\n",
              "      <td>Negative</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>But here’s the thing, if we embrace the AI, ho...</td>\n",
              "      <td>Negative</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>413</th>\n",
              "      <td>AI is useful, pero dapat may balance sa paggam...</td>\n",
              "      <td>Negative</td>\n",
              "      <td>nan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>414</th>\n",
              "      <td>Hindi pa tayo masyadong advanced sa Pilipinas,...</td>\n",
              "      <td>Negative</td>\n",
              "      <td>nan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>415</th>\n",
              "      <td>Kailangan lang na maayos ang paggamit ng AI pa...</td>\n",
              "      <td>Negative</td>\n",
              "      <td>nan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>429</th>\n",
              "      <td>AI can be a powerful tool to enhance learning ...</td>\n",
              "      <td>Negative</td>\n",
              "      <td>nan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>430</th>\n",
              "      <td>Pinangunahan ni Mayor Joy Belmonte ang turnove...</td>\n",
              "      <td>Positive</td>\n",
              "      <td>X/Twitter</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1110 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-76c43f2b-24c1-4e37-8748-bb747c6e47fc')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-76c43f2b-24c1-4e37-8748-bb747c6e47fc button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-76c43f2b-24c1-4e37-8748-bb747c6e47fc');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f3084380-022e-4323-bbe3-0ba23e26f5bc\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f3084380-022e-4323-bbe3-0ba23e26f5bc')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f3084380-022e-4323-bbe3-0ba23e26f5bc button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_44674815-ebda-4ac5-a016-f07eb30fb992\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('dataset')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_44674815-ebda-4ac5-a016-f07eb30fb992 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('dataset');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "dataset",
              "summary": "{\n  \"name\": \"dataset\",\n  \"rows\": 1110,\n  \"fields\": [\n    {\n      \"column\": \"Content\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 985,\n        \"samples\": [\n          \"No, Mas Malino Chatppt in Tipid SA ORAS\",\n          \"Increased dependence and decrease to think of the box\",\n          \"AI can be a powerful tool to improve learning skills and critical thinking.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sentiment\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Positive\",\n          \"Negative\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Platform\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 14,\n        \"samples\": [\n          \"education next\",\n          \"nan\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.to_csv('augmented.csv',index=0) ##WE WILL SAVE AUGMENTED DATASET IN OUR LOCAL STORAGE TO MAKE REPLICATION OR TESTING EASIER IN THE FUTURE SO THAT AUGMENTATION WILL NOT BE NEEDED TO RUN AGAIN"
      ],
      "metadata": {
        "id": "vj0TKmV8N-nj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "JHHAzNx4OYmT",
        "outputId": "a4d66cec-6750-4b21-b890-0ffaac121664"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Content      1110\n",
              "Sentiment    1110\n",
              "Platform      370\n",
              "dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Content</th>\n",
              "      <td>1110</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sentiment</th>\n",
              "      <td>1110</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Platform</th>\n",
              "      <td>370</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(text):\n",
        "\n",
        "    #Determine the language of the sentence\n",
        "    lang = detect(text)\n",
        "\n",
        "\n",
        "    # Remove any character that is not a letter or whitespace using regex\n",
        "    # This step removes punctuation, numbers, and special characters, leaving only letters and spaces.\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "\n",
        "    # Initialize the WordNet Lemmatizer (for reducing words to their base form)\n",
        "    le = WordNetLemmatizer()\n",
        "\n",
        "    # Tokenize the text into individual words\n",
        "    word_tokens = word_tokenize(text)\n",
        "\n",
        "    # Lemmatize each word token and remove stopwords (words in 'all_stopwords') and tokens shorter than 3 characters\n",
        "    tokens = [le.lemmatize(w) for w in word_tokens if w not in all_stopwords and len(w) > 3]\n",
        "\n",
        "    # Stemming based on language\n",
        "    if lang == 'en':\n",
        "        # For other languages (assumed to be English), use the PorterStemmer for stemming\n",
        "        ps = PorterStemmer()\n",
        "        stemmed_tokens = [ps.stem(token) for token in tokens]\n",
        "\n",
        "    else:\n",
        "        # If the language is English, use the Tagalog stemmer ('stemmer' assumed to be the English stemmer)\n",
        "        stemmed_tokens = [stemmer.get_stem(token) for token in tokens]\n",
        "\n",
        "    # Join the processed tokens back into a single string\n",
        "    cleaned_text = \" \".join(stemmed_tokens)\n",
        "\n",
        "    # Return the cleaned and processed text\n",
        "    return cleaned_text\n"
      ],
      "metadata": {
        "id": "hb64R8aTOb0W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Applying the 'clean_text' function to the 'Content' column of the dataset\n",
        "# For each row in the 'Content' column, it calls the 'clean_text' function, specifying \"english\" as the language.\n",
        "dataset['Content'] = dataset['Content'].apply(lambda x: clean_text(x))\n"
      ],
      "metadata": {
        "id": "mPu-h5bgOclE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initializing the TfidfVectorizer\n",
        "# This vectorizer converts the text into a matrix of TF-IDF features.\n",
        "# 'stop_words=all_stopwords' specifies that the TF-IDF vectorizer should ignore both English and Tagalog stopwords.\n",
        "# 'max_features=1000' limits the number of features (terms) to 1000, keeping only the most important ones based on TF-IDF scores.\n",
        "vect = TfidfVectorizer(stop_words=all_stopwords, max_features=1000)\n",
        "\n",
        "# Applying the vectorizer to the 'Content' column of the English dataset\n",
        "# The fit_transform method learns the vocabulary and creates the document-term matrix (DTM) based on TF-IDF scores.\n",
        "vect_text = vect.fit_transform(dataset['Content'])\n"
      ],
      "metadata": {
        "id": "pptMUQ8cOugT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Printing the shape of the TF-IDF matrix\n",
        "# This will show the dimensions of the matrix, where the first number is the number of documents and the second number is the number of features (terms).\n",
        "print(vect_text.shape)\n",
        "\n",
        "# Printing the TF-IDF matrix\n",
        "# This will display the sparse matrix representation of the TF-IDF features.\n",
        "# Each row corresponds to a document, and each column corresponds to a term, with values representing the TF-IDF scores.\n",
        "print(vect_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J2t4zic8Ow5e",
        "outputId": "6539318f-8861-4710-d065-da322d7304d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1110, 1000)\n",
            "  (0, 991)\t0.3514417421535532\n",
            "  (0, 47)\t0.40093425990231\n",
            "  (0, 140)\t0.33681888659415954\n",
            "  (0, 13)\t0.31056237756196853\n",
            "  (0, 230)\t0.41526267129221534\n",
            "  (0, 897)\t0.5526392159704392\n",
            "  (0, 247)\t0.16730594486754566\n",
            "  (1, 939)\t0.3191882648887706\n",
            "  (1, 874)\t0.2930710561317415\n",
            "  (1, 102)\t0.33466371656565197\n",
            "  (1, 382)\t0.43096010153929615\n",
            "  (1, 788)\t0.26477061942498026\n",
            "  (1, 350)\t0.26477061942498026\n",
            "  (1, 737)\t0.2853731479103198\n",
            "  (1, 409)\t0.3263713979783511\n",
            "  (1, 592)\t0.36139130735985536\n",
            "  (1, 370)\t0.17046267447413638\n",
            "  (1, 935)\t0.1633325139055952\n",
            "  (2, 111)\t0.3210613031038277\n",
            "  (2, 883)\t0.1296342118111935\n",
            "  (2, 255)\t0.37605929251133546\n",
            "  (2, 800)\t0.33309573562451394\n",
            "  (2, 251)\t0.3248190178593697\n",
            "  (2, 155)\t0.32881932905164113\n",
            "  (2, 318)\t0.3856140619566219\n",
            "  :\t:\n",
            "  (1106, 678)\t0.6873471346327641\n",
            "  (1107, 84)\t0.5330813107041159\n",
            "  (1107, 387)\t0.5626451705640386\n",
            "  (1107, 952)\t0.3891941441390911\n",
            "  (1107, 336)\t0.303934430503286\n",
            "  (1107, 902)\t0.39421632175929705\n",
            "  (1108, 260)\t0.4915914442174704\n",
            "  (1108, 705)\t0.485610899332838\n",
            "  (1108, 853)\t0.34884412761788647\n",
            "  (1108, 189)\t0.4104650101661418\n",
            "  (1108, 931)\t0.3086606925682375\n",
            "  (1108, 484)\t0.24064649704387833\n",
            "  (1108, 935)\t0.2813609724197111\n",
            "  (1109, 513)\t0.2687903774387598\n",
            "  (1109, 638)\t0.2687903774387598\n",
            "  (1109, 808)\t0.2687903774387598\n",
            "  (1109, 468)\t0.2687903774387598\n",
            "  (1109, 538)\t0.5609184411438793\n",
            "  (1109, 555)\t0.2687903774387598\n",
            "  (1109, 646)\t0.2687903774387598\n",
            "  (1109, 486)\t0.22098225320204812\n",
            "  (1109, 819)\t0.23589775606566368\n",
            "  (1109, 740)\t0.2523440667522117\n",
            "  (1109, 60)\t0.1734148512919918\n",
            "  (1109, 549)\t0.23162416571238165\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##Text Classification MODEL COMPARISON"
      ],
      "metadata": {
        "id": "Mb3LdI3MOzE1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Splitting of dataset\n",
        "X_data, X_unseen, y_data, y_unseen = train_test_split(vect_text, dataset['Sentiment'], test_size=0.1, random_state=0)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.2, random_state=0)"
      ],
      "metadata": {
        "id": "qZVhgJxIPA7k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Training and evaluation of Model (Decision Tree)\n",
        "from sklearn import tree\n",
        "tree = tree.DecisionTreeClassifier()\n",
        "tree.fit(X_train,y_train)\n",
        "\n",
        "y_pred = tree.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "y_pred_unseen = tree.predict(X_unseen)\n",
        "accuracy_unseen = accuracy_score(y_unseen,y_pred_unseen)\n",
        "print(f\"Test Accuracy: {accuracy}\")\n",
        "print(f\"Unseen Accuracy: {accuracy_unseen}\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(classification_report(y_unseen, y_pred_unseen))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hHf74aAePD9Y",
        "outputId": "6b4d5cc1-f676-47d9-9266-6685dfad24d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.905\n",
            "Unseen Accuracy: 0.8918918918918919\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.93      0.86      0.89        92\n",
            "    Positive       0.89      0.94      0.91       108\n",
            "\n",
            "    accuracy                           0.91       200\n",
            "   macro avg       0.91      0.90      0.90       200\n",
            "weighted avg       0.91      0.91      0.90       200\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.93      0.83      0.88        52\n",
            "    Positive       0.86      0.95      0.90        59\n",
            "\n",
            "    accuracy                           0.89       111\n",
            "   macro avg       0.90      0.89      0.89       111\n",
            "weighted avg       0.90      0.89      0.89       111\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Training and evaluation of Model (Logistic Regression)\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "LR = LogisticRegression().fit(X_train,y_train)\n",
        "\n",
        "y_pred = LR.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "y_pred_unseen = LR.predict(X_unseen)\n",
        "accuracy_unseen = accuracy_score(y_unseen,y_pred_unseen)\n",
        "print(f\"Test Accuracy: {accuracy}\")\n",
        "print(f\"Unseen Accuracy: {accuracy_unseen}\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(classification_report(y_unseen, y_pred_unseen))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_pf0oUeU0Yy",
        "outputId": "1a7d023b-5318-48c8-c55d-76fd831ee6ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.925\n",
            "Unseen Accuracy: 0.8648648648648649\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.94      0.89      0.92        92\n",
            "    Positive       0.91      0.95      0.93       108\n",
            "\n",
            "    accuracy                           0.93       200\n",
            "   macro avg       0.93      0.92      0.92       200\n",
            "weighted avg       0.93      0.93      0.92       200\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.85      0.87      0.86        52\n",
            "    Positive       0.88      0.86      0.87        59\n",
            "\n",
            "    accuracy                           0.86       111\n",
            "   macro avg       0.86      0.86      0.86       111\n",
            "weighted avg       0.87      0.86      0.86       111\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rfc = RandomForestClassifier()\n",
        "rfc.fit(X_train,y_train)\n",
        "\n",
        "y_pred = rfc.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "y_pred_unseen = rfc.predict(X_unseen)\n",
        "accuracy_unseen = accuracy_score(y_unseen,y_pred_unseen)\n",
        "print(f\"Test Accuracy: {accuracy}\")\n",
        "print(f\"Unseen Accuracy: {accuracy_unseen}\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(classification_report(y_unseen, y_pred_unseen))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AJ8VSLSTXI6-",
        "outputId": "78df7bb5-b872-49b7-fa28-0317bb1b5043"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.94\n",
            "Unseen Accuracy: 0.918918918918919\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.97      0.90      0.93        92\n",
            "    Positive       0.92      0.97      0.95       108\n",
            "\n",
            "    accuracy                           0.94       200\n",
            "   macro avg       0.94      0.94      0.94       200\n",
            "weighted avg       0.94      0.94      0.94       200\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.91      0.92      0.91        52\n",
            "    Positive       0.93      0.92      0.92        59\n",
            "\n",
            "    accuracy                           0.92       111\n",
            "   macro avg       0.92      0.92      0.92       111\n",
            "weighted avg       0.92      0.92      0.92       111\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6eB1HoHKXrw5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}